{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Homework 1. Which of two things is larger?\n",
      "\n",
      "Due: Thursday, September 19, 11:59 PM\n",
      "\n",
      "<a href=https://raw.github.com/cs109/content/master/HW1.ipynb download=HW1.ipynb> Download this assignment</a>\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Useful libraries for this assignment\n",
      "\n",
      "* [numpy](http://docs.scipy.org/doc/numpy-dev/user/index.html), for arrays\n",
      "* [pandas](http://pandas.pydata.org/), for data frames\n",
      "* [matplotlib](http://matplotlib.org/), for plotting\n",
      "* [requests](http://docs.python-requests.org/en/latest/), for downloading web content\n",
      "* [pattern](http://www.clips.ua.ac.be/pages/pattern), for parsing html and xml pages\n",
      "* [fnmatch](http://docs.python.org/2/library/fnmatch.html) (optional), for Unix-style string matching"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# special IPython command to prepare the notebook for matplotlib\n",
      "%matplotlib inline \n",
      "\n",
      "from fnmatch import fnmatch\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import requests\n",
      "from pattern import web\n",
      "from collections import defaultdict\n",
      "\n",
      "# set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = True\n",
      "rcParams['axes.facecolor'] = '#eeeeee'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Introduction\n",
      "\n",
      "This was the [XKCD comic](http://xkcd.com/1131/) after the 2012 Presidential election:\n",
      "\n",
      "<img src=\"http://imgs.xkcd.com/comics/math.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The comic refers to the fact that Nate Silver's statistical model (which is based mostly on combining information from pre-election polls) correctly predicted the outcome of the 2012 presidential race in all 50 states. \n",
      "\n",
      "Polling data isn't a perfect predictor for the future, and some polls are more accurate than others. This means that election forecastors must consider prediction uncertainty when building models.\n",
      "\n",
      "In this first assignment, you will perform a simple analysis of polling data about the upcoming <a href=\"http://en.wikipedia.org/wiki/Governor_(United_States)\">Governor races</a>. The assignment has three main parts:\n",
      "\n",
      "**First** you will build some tools to download historical polling data from the web, and parse it into a more convenient format. \n",
      "\n",
      "**Next** you will use these tools to aggregate and visualize several past Governor races\n",
      "\n",
      "**Finally** you will run a bootstrap analysis to estimate the probable outcome of current Governor races, given the level of precision of historical polls.\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "## Part 1: Collect and Clean\n",
      "\n",
      "The [Real Clear Politics](http://www.realclearpolitics.com) website archives many political polls. In addition, they combine related polls to form an \"RCP average\" estimate of public opinion over time. For example, the chart on [this page](http://www.realclearpolitics.com/epolls/2012/president/us/general_election_romney_vs_obama-1171.html) shows historical polling data for the Obama-Romney presidential race. The chart is an average of the polling data table below the chart.\n",
      "\n",
      "The data used to generate plots like this are stored as XML pages, with URLs like:\n",
      "\n",
      "http://charts.realclearpolitics.com/charts/[id].xml\n",
      "\n",
      "Here, [id] is a unique integer, found at the end of the URL of the page that displays the graph. The id for the Obama-Romney race is 1171:\n",
      "\n",
      "http://charts.realclearpolitics.com/charts/1171.xml\n",
      "\n",
      "Opening this page in Google Chrome or Firefox will show you the XML content in an easy-to-read format. Notice that XML tags are nested inside each other, hierarchically (the jargony term for this is the \"Document Object Model\", or \"DOM\"). The first step of webscraping is almost always exploring the HTML/XML source in a browser, and getting a sense of this hierarchy.\n",
      "\n",
      "---\n",
      "\n",
      "#### Problem 0\n",
      "\n",
      "The above XML page includes 5 distinct tags (one, for example, is `chart`). List these tags, and depict how they nest inside each other using an indented list. For example:\n",
      "\n",
      "* Page\n",
      "  * Section\n",
      "     * Paragraph\n",
      "  * Conclusion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Your Answer Here*\n",
      "\n",
      "* Chart\n",
      "  * Series\n",
      "      * Value\n",
      "  * Graphs\n",
      "      * Graph\n",
      "          * Value\n",
      "      * Graph\n",
      "          * Value"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "#### Problem 1\n",
      "\n",
      "We want to download and work with poll data like this. Like most programming tasks, we will break this into many smaller, easier pieces\n",
      "\n",
      "Fill in the code for the `get_poll_xml` function, that finds and downloads an XML page discussed above\n",
      "\n",
      "**Hint** \n",
      "\n",
      "`requests.get(\"http://www.google.com\").text` downloads the text from Google's homepage"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function\n",
      "--------\n",
      "get_poll_xml\n",
      "\n",
      "Given a poll_id, return the XML data as a text string\n",
      "\n",
      "Inputs\n",
      "------\n",
      "poll_id : int\n",
      "    The ID of the poll to fetch\n",
      "\n",
      "Returns\n",
      "-------\n",
      "xml : str\n",
      "    The text of the XML page for that poll_id\n",
      "\n",
      "Example\n",
      "-------\n",
      ">>> get_poll_xml(1044)\n",
      "u'<?xml version=\"1.0\" encoding=\"UTF-8\"?><chart><series><value xid=\\'0\\'>1/27/2009</value>\n",
      "...etc...\n",
      "\"\"\"    \n",
      "#your code here\n",
      "#import requests\n",
      "\n",
      "def get_poll_xml(id):\n",
      "    poll_id=str(id) #convert the integers to string so it can be concatenated \n",
      "    xml=requests.get(\"http://charts.realclearpolitics.com/charts/\"+poll_id+\".xml\").text #split the url to include \"Input\" and concatenate\n",
      "    return xml\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are some other functions we'll use later. `plot_colors` contains hints about parsing XML data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \"r\"egular \"e\"xpressions is kind of a mini-language to\n",
      "# do pattern matching on text\n",
      "import re\n",
      "\n",
      "def _strip(s):\n",
      "    \"\"\"This function removes non-letter characters from a word\n",
      "    \n",
      "    for example _strip('Hi there!') == 'Hi there'\n",
      "    \"\"\"\n",
      "    return re.sub(r'[\\W_]+', '', s)\n",
      "\n",
      "def plot_colors(xml):\n",
      "    \"\"\"\n",
      "    Given an XML document like the link above, returns a python dictionary\n",
      "    that maps a graph title to a graph color.\n",
      "    \n",
      "    Both the title and color are parsed from attributes of the <graph> tag:\n",
      "    <graph title=\"the title\", color=\"#ff0000\"> -> {'the title': '#ff0000'}\n",
      "    \n",
      "    These colors are in \"hex string\" format. This page explains them:\n",
      "    http://coding.smashingmagazine.com/2012/10/04/the-code-side-of-color/\n",
      "    \n",
      "    Example\n",
      "    -------\n",
      "    >>> plot_colors(get_poll_xml(1044))\n",
      "    {u'Approve': u'#000000', u'Disapprove': u'#FF0000'}\n",
      "    \"\"\"\n",
      "    dom = web.Element(xml)\n",
      "    result = {}\n",
      "    for graph in dom.by_tag('graph'):\n",
      "        title = _strip(graph.attributes['title'])\n",
      "        result[title] = graph.attributes['color']\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "#### Problem 2\n",
      "\n",
      "Even though `get_poll_xml` pulls data from the web into Python, it does so as a block of text. This still isn't very useful. Use the `web` module in `pattern` to parse this text, and extract data into a pandas DataFrame.\n",
      "\n",
      "**Hints**\n",
      "\n",
      "* You might want create python lists for each column in the XML. Then, to turn these lists into a DataFrame, run\n",
      "\n",
      "`pd.DataFrame({'column_label_1': list_1, 'column_label_2':list_2, ...})`\n",
      "\n",
      "* use the pandas function `pd.to_datetime` to convert strings into dates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "    Function\n",
      "    ---------\n",
      "    rcp_poll_data\n",
      "\n",
      "    Extract poll information from an XML string, and convert to a DataFrame\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    xml : str\n",
      "        A string, containing the XML data from a page like \n",
      "        get_poll_xml(1044)\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    A pandas DataFrame with the following columns:\n",
      "        date: The date for each entry\n",
      "        title_n: The data value for the gid=n graph (take the column name from the `title` tag)\n",
      "        \n",
      "    This DataFrame should be sorted by date\n",
      "        \n",
      "    Example\n",
      "    -------\n",
      "    Consider the following simple xml page:\n",
      "    \n",
      "    <chart>\n",
      "    <series>\n",
      "    <value xid=\"0\">1/27/2009</value>\n",
      "    <value xid=\"1\">1/28/2009</value>\n",
      "    </series>\n",
      "    <graphs>\n",
      "    <graph gid=\"1\" color=\"#000000\" balloon_color=\"#000000\" title=\"Approve\">\n",
      "    <value xid=\"0\">63.3</value>\n",
      "    <value xid=\"1\">63.3</value>\n",
      "    </graph>\n",
      "    <graph gid=\"2\" color=\"#FF0000\" balloon_color=\"#FF0000\" title=\"Disapprove\">\n",
      "    <value xid=\"0\">20.0</value>\n",
      "    <value xid=\"1\">20.0</value>\n",
      "    </graph>\n",
      "    </graphs>\n",
      "    </chart>\n",
      "    \n",
      "    Given this string, rcp_poll_data should return\n",
      "    result = pd.DataFrame({'date': pd.to_datetime(['1/27/2009', '1/28/2009']), \n",
      "                           'Approve': [63.3, 63.3], 'Disapprove': [20.0, 20.0]})\n",
      "\"\"\"\n",
      "#your code here\n",
      "\n",
      "\"\"\"\n",
      "#my failed attempts, but it took me a long long time and i didn't want to just delete it\n",
      "\n",
      "    import pandas as pd\n",
      "    import pattern\n",
      "    \n",
      "    xml=get_poll_xml(xml)\n",
      "    date=[]\n",
      "    nominees=[]\n",
      "    obama=[]\n",
      "    romney=[]\n",
      "    \n",
      "    from pattern.web import Element\n",
      "    dom=Element(xml)\n",
      "    for i in dom('series'):\n",
      "        for j in i('value'):\n",
      "            date.append(pd.to_datetime(j.content))\n",
      "            \n",
      "    for i in dom('graphs'):\n",
      "        for j in i('graph'):\n",
      "            for k in j('value'):\n",
      "                nominees.append(k.content)      \n",
      "                \n",
      "    obama=nominees[:len(nominees)/2]\n",
      "    romney=nominees[len(nominees)/2:]\n",
      "    \n",
      "    obama=filter(None,obama)\n",
      "    romney=filter(None,romney)\n",
      "    \n",
      "    result = pd.DataFrame({'Date':date,'Obama':obama,'Romney':romney})\n",
      "    \n",
      "    return result\n",
      "\"\"\"\n",
      "\n",
      "def rcp_poll_data(xml):\n",
      "    \n",
      "    #xml=get_poll_xml(1171)    \n",
      "    candidates=[]\n",
      "    titles=[]\n",
      "    date=[]\n",
      "    candidate1=[]\n",
      "    candidate2=[]\n",
      "    candidate3=[]\n",
      "    heading=['date']   #created a list to avoid hard coding title in DataFrame\n",
      "    \n",
      "    #storing the xml data in dom as element to further extract using tags, content and other features\n",
      "    from pattern.web import Element\n",
      "    dom=Element(xml)\n",
      "    \n",
      "    #using try/except to avoid breaking of codes because of links with missing data\n",
      "    try:\n",
      "        for dt in dom.by_tag('series'):    #seeking the tag \"series\" and then \"values\" which are stored under series\n",
      "            for d in dt('value'):          #this loop will get all the values under series and append its \"content\" to the list date\n",
      "                date.append(d.content)\n",
      "            \n",
      "        for i in dom.by_tag('graphs'):     #performing same function as above but this time fetching the polling data for candidates\n",
      "            for j in i.by_tag('graph'):    #putting polling data for all the candidates in one list \"candidates\" as elements\n",
      "                titles.append(j.title)     #storing titles of the graphs in the list titles\n",
      "                candidates.append(j)\n",
      "        \n",
      "        for u in candidates[0]:      #extracting data for candidate 1 from the list candidates and converting values to float from unicode\n",
      "            try:                       #using try/except to avoid code breaking at emptry strings\n",
      "                candidate1.append(float(u.content))\n",
      "            except ValueError:\n",
      "                candidate1.append(float('NaN'))   #converting empty strings to float as well \n",
      "                \n",
      "        for v in candidates[1]:           #doing same thing as above for candidate 2\n",
      "            try:\n",
      "                candidate2.append(float(v.content))\n",
      "            except ValueError:\n",
      "                candidate2.append(float('NaN'))   \n",
      "        \n",
      "        if len(candidates)==3:            #checking to see if candidate 3 exists, if it does, adding its title to the list titles\n",
      "             \n",
      "            for w in candidates[2]:   #again extracting data for candidate 3 and storing it in seperate list\n",
      "                try:\n",
      "                    candidate3.append(float(w.content))\n",
      "                except ValueError:\n",
      "                    candidate3.append(float('NaN')) \n",
      "        elif len(candidates)==2:              #if candidate 3 doesn't exists, making an empty list using candidate 2 as referece\n",
      "            titles.append(unicode('Nan'))\n",
      "            for w in candidates[1]:             #this is important because you want to add all the lists to one dataframe \n",
      "                try:                              # I probably could have used if statements to create 2 versions of dataframe as well\n",
      "                    candidate3.append(float('NaN'))\n",
      "                except ValueError:\n",
      "                    candidate3.append(float('NaN'))  \n",
      "        \n",
      "        if len(candidates)==3:result = pd.DataFrame({heading[0]:pd.to_datetime(date),titles[0]:candidate1,titles[1]:candidate2,titles[2]:candidate3})\n",
      "        elif len(candidates)==2:result = pd.DataFrame({heading[0]:pd.to_datetime(date),titles[0]:candidate1,titles[1]:candidate2})\n",
      "        \n",
      "    except IndexError:\n",
      "        pass\n",
      "    \n",
      "    return result\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def poll_plot(poll_id):\n",
      "    \"\"\"\n",
      "    Make a plot of an RCP Poll over time\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    poll_id : int\n",
      "        An RCP poll identifier\n",
      "    \"\"\"\n",
      "\n",
      "    # hey, you wrote two of these functions. Thanks for that!\n",
      "    xml = get_poll_xml(poll_id)\n",
      "    data = rcp_poll_data(xml)\n",
      "    colors = plot_colors(xml)\n",
      "\n",
      "    #remove characters like apostrophes\n",
      "    data = data.rename(columns = {c: _strip(c) for c in data.columns})\n",
      "\n",
      "    #normalize poll numbers so they add to 100   \n",
      "    norm = data[colors.keys()].sum(axis=1) / 100    \n",
      "    for c in colors.keys():\n",
      "        data[c] /= norm\n",
      "    \n",
      "    for label, color in colors.items():\n",
      "        plt.plot(data.date, data[label], color=color, label=label)        \n",
      "        \n",
      "    plt.xticks(rotation=70)\n",
      "    plt.legend(loc='best')\n",
      "    plt.xlabel(\"Date\")\n",
      "    plt.ylabel(\"Normalized Poll Percentage\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output from `rcp_poll_data` is much more useful for analysis. For example, we can plot with it:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you've done everything right so far, the following code should reproduce the graph on [this page](http://www.realclearpolitics.com/epolls/other/president_obama_job_approval-1044.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "poll_plot(1044)\n",
      "plt.title(\"Obama Job Approval\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "UnboundLocalError",
       "evalue": "local variable 'result' referenced before assignment",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-8ca48b980fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoll_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1044\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Obama Job Approval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-15-b6c3d1f512a4>\u001b[0m in \u001b[0;36mpoll_plot\u001b[0;34m(poll_id)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# hey, you wrote two of these functions. Thanks for that!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mxml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_poll_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcp_poll_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-14-19242b03b723>\u001b[0m in \u001b[0;36mrcp_poll_data\u001b[0;34m(xml)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'result' referenced before assignment"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Part 2: Aggregate and Visualize\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Problem 3\n",
      "\n",
      "Unfortunately, these data don't have any error bars. If a candidate leads by 10% in the RCP average, is she a shoo-in to win? Or is this number too close to call? Does a 10% poll lead mean more 1 day before a race than it does 1 week before? Without error estimates, these questions are impossible to answer.\n",
      "\n",
      "To get a sense of how accurate the RCP polls are, you will gather data from many previous Governor races, where the outcome is known.\n",
      "\n",
      "This url has links to many governer races. \n",
      "\n",
      "http://www.realclearpolitics.com/epolls/2010/governor/2010_elections_governor_map.html\n",
      "\n",
      "Notice that each link to a governor race has the following URL pattern:\n",
      "\n",
      "http://www.realclearpolitics.com/epolls/[YEAR]/governor/[STATE]/[TITLE]-[ID].html\n",
      "\n",
      "\n",
      "Write a function that scans html for links to URLs like this\n",
      "\n",
      "**Hint** The [fnmatch](http://docs.python.org/2/library/fnmatch.html) function is useful for simple string matching tasks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "    Function\n",
      "    --------\n",
      "    find_governor_races\n",
      "\n",
      "    Find and return links to RCP races on a page like\n",
      "    http://www.realclearpolitics.com/epolls/2010/governor/2010_elections_governor_map.html\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    html : str\n",
      "        The HTML content of a page to scan\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    A list of urls for Governer race pages\n",
      "    \n",
      "    Example\n",
      "    -------\n",
      "    For a page like\n",
      "    \n",
      "    <html>\n",
      "    <body>\n",
      "    <a href=\"http://www.realclearpolitics.com/epolls/2010/governor/ma/massachusetts_governor_baker_vs_patrick_vs_cahill-1154.html\"></a>\n",
      "    <a href=\"http://www.realclearpolitics.com/epolls/2010/governor/ca/california_governor_whitman_vs_brown-1113.html\"></a>\n",
      "    </body>\n",
      "    </html>\n",
      "    \n",
      "    find_governor_races would return\n",
      "    ['http://www.realclearpolitics.com/epolls/2010/governor/ma/massachusetts_governor_baker_vs_patrick_vs_cahill-1154.html',\n",
      "     'http://www.realclearpolitics.com/epolls/2010/governor/ca/california_governor_whitman_vs_brown-1113.html']\n",
      "\"\"\"\n",
      "#your code here\n",
      "\n",
      "\n",
      "def find_governor_races(page):\n",
      "    \n",
      "    import re\n",
      "    \n",
      "    #page=requests.get(page).text  #stores the page info as text, \n",
      "    #i put this in quote because when the plot functions calls on this, it is storing it as text instead of just calling the link\n",
      "    links=[]\n",
      "    \n",
      "    #uses the findall function in re to locate the links in \"page\" by applying the pattern i created but stores them as tuples as \n",
      "    #individual entires\n",
      "    \n",
      "    tuples=re.findall('(http://www.realclearpolitics.com/epolls/)(\\d+)(/governor/)(\\w+)(/)(\\w+)(-)(\\d+)(.html)',page)\n",
      "    \n",
      "    #this loop joins those individual entries in each tiple to create a link  \n",
      "    for i in tuples:\n",
      "        t=''.join(i)\n",
      "        if str(t) not in links:         # if statement checks to see if the link already exists in the list to avoid duplication\n",
      "            links.append(str(t))\n",
      "    \n",
      "    return links\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Problem 4\n",
      "\n",
      "At this point, you have functions to find a collection of governor races, download historical polling data from each one,\n",
      "parse them into a numerical DataFrame, and plot this data.\n",
      "\n",
      "The main question we have about these data are how accurately they predict election outcomes. To answer this question, we\n",
      "need to grab the election outcome data.\n",
      "\n",
      "Write a function that looks up and returns the election result on a page like [this one](http://www.realclearpolitics.com/epolls/2010/governor/ca/california_governor_whitman_vs_brown-1113.html). \n",
      "\n",
      "**Remember to look at the HTML source!**\n",
      "\n",
      "You can do this by selection `view->developer->view source` in Chrome, or `Tools -> web developer -> page source` in Firefox. Altenatively, you can right-click on a part of the page, and select \"inspect element\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "    Function\n",
      "    --------\n",
      "    race_result\n",
      "\n",
      "    Return the actual voting results on a race page\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    url : string\n",
      "        The website to search through\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    A dictionary whose keys are candidate names,\n",
      "    and whose values is the percentage of votes they received.\n",
      "    \n",
      "    If necessary, normalize these numbers so that they add up to 100%.\n",
      "    \n",
      "    Example\n",
      "    --------\n",
      "    >>> url = 'http://www.realclearpolitics.com/epolls/2010/governor/ca/california_governor_whitman_vs_brown-1113.html'\n",
      "    >>> race_result(url)\n",
      "    {'Brown': 56.0126582278481, 'Whitman': 43.9873417721519}\n",
      "\"\"\"\n",
      "#your code here\n",
      "\n",
      "\n",
      "'''\n",
      "\n",
      "test=[]\n",
      "\n",
      "for i in eList[0:1]:\n",
      "    try:\n",
      "        html=requests.get(i).text\n",
      "        tuples=re.findall('Final Results</a></td><td>--</td><td>--</td><td>(\\d+.\\d+)</td><td>(\\d+.\\d+)</td><td>(\\d+.\\d+)',html)\n",
      "        vs=re.findall('Sample</th><th>(..\\w+)....</th><th>(\\w+)....</th><th>(\\w+)',html)\n",
      "        race_result[str(vs[0][0])]=str(tuples[0][0])\n",
      "        race_result[str(vs[0][1])]=str(tuples[0][1])\n",
      "        race_result[str(vs[0][2])]=str(tuples[0][2])\n",
      "    except IndexError:\n",
      "        try:\n",
      "            html=requests.get(i).text\n",
      "            tuples=re.findall('Final Results</a></td><td>--</td><td>--</td><td>(\\d+.\\d+)</td><td>(\\d+.\\d+)',html)\n",
      "            vs=re.findall('Sample</th><th>(..\\w+)....</th><th>(\\w+)',html)\n",
      "            race_result[str(vs[0][0])]=str(tuples[0][0])\n",
      "            race_result[str(vs[0][1])]=str(tuples[0][1])\n",
      "        except IndexError:\n",
      "            try:\n",
      "                html=requests.get(i).text\n",
      "                tuples=re.findall('Final Results</td><td>--</td><td>--</td><td>(\\d+.\\d+)</td><td>(\\d+.\\d+)</td><td>(\\d+.\\d+)',html)\n",
      "                vs=re.findall('Sample</th><th>(..\\w+)....</th><th>(\\w+).</th><th>(\\w+)',html)\n",
      "                race_result[str(vs[0][0])]=str(tuples[0][0])\n",
      "                race_result[str(vs[0][1])]=str(tuples[0][1])\n",
      "                race_result[str(vs[0][2])]=str(tuples[0][2])\n",
      "            except IndexError:\n",
      "                html=requests.get(i).text\n",
      "                tuples=re.findall('Final Results</td><td>--</td><td>--</td><td>(\\d+.\\d+)</td><td>(\\d+.\\d+)',html)\n",
      "                vs=re.findall('Sample</th><th>(..\\w+)....</th><th>(\\w+)',html)\n",
      "                race_result[str(vs[0][0])]=str(tuples[0][0])\n",
      "                race_result[str(vs[0][1])]=str(tuples[0][1])\n",
      "                            \n",
      "    return race_result\n",
      "\n",
      "'''\n",
      "#def table_type(tbl):\n",
      "    ### Extract the table type\n",
      " #   return tbl('th')[3].content\n",
      "#url = requests.get('http://www.realclearpolitics.com/epolls/2010/governor/2010_elections_governor_map.html').text.encode('ascii', 'ignore')\n",
      "\n",
      "\n",
      "def race_result(url):\n",
      "    \n",
      "    import re\n",
      "    import sys\n",
      "    eList=find_governor_races(url) #makes a list of all the links for pages of all elections \n",
      "    race_result={}\n",
      "        \n",
      "    for i in eList:     # loops through the list of links and to get fetches the the table element\n",
      "        html=requests.get(i).text   \n",
      "        dom=web.Element(html)\n",
      "        tbls=dom.by_class('data layout')\n",
      "    \n",
      "        for tbl in tbls:            #for the tables, grabs the heading and the first row and stores it\n",
      "            table_headers=tbl('tr')[0]('th')    #access the headings in html\n",
      "            names=[val.content for val in table_headers]   #stores the headings in names\n",
      "            table_data=tbl('tr')[1]('td')\n",
      "            data=[val.content for val in table_data]  #stores the first row which is final results in data\n",
      "            \n",
      "        data_int=[]    #this for loop converts the values to float and if there is a error, stores it as string. \n",
      "        for d in data:\n",
      "            try:\n",
      "                data_int.append(float(d))\n",
      "            except ValueError:            #error is for the last entry in table \"candidate +12\"\n",
      "                data_int.append(str(d))\n",
      "            \n",
      "        i=3                        # to only catch values from column 4 and onward\n",
      "        for n in names[3:]:        #starts from 4th entry in the list to only capture the candidates\n",
      "            if str(n)!='Spread':   #if the loop has reached last column \"Spread\" it will stop, this allows capturing of all the candidates\n",
      "                race_result[str(n.split()[0])]=data_int[i]      #uses split function to take away the initials of last name with brackets \"(R)\"\n",
      "                i+=1\n",
      "           \n",
      "    raw=sum(race_result.values())    #uses factor and multiplication to normalize the function to add up to 100        \n",
      "    factor=1.0/raw\n",
      "    for key in race_result:\n",
      "        race_result[key]=race_result[key]*factor*100\n",
      "    \n",
      "    return race_result\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Here are some more utility functions that take advantage of what you've done so far."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def id_from_url(url):\n",
      "    \"\"\"Given a URL, look up the RCP identifier number\"\"\"\n",
      "    return url.split('-')[-1].split('.html')[0]\n",
      "\n",
      "\n",
      "def plot_race(url):\n",
      "    \"\"\"Make a plot summarizing a senate race\n",
      "    \n",
      "    Overplots the actual race results as dashed horizontal lines\n",
      "    \"\"\"\n",
      "    #hey, thanks again for these functions!\n",
      "    id = id_from_url(url)\n",
      "    xml = get_poll_xml(id)    \n",
      "    colors = plot_colors(xml)\n",
      "\n",
      "    if len(colors) == 0:\n",
      "        return\n",
      "    \n",
      "    #really, you shouldn't have\n",
      "    result = race_result(url)\n",
      "    \n",
      "    poll_plot(id)\n",
      "    plt.xlabel(\"Date\")\n",
      "    plt.ylabel(\"Polling Percentage\")\n",
      "    for r in result:\n",
      "        plt.axhline(result[r], color=colors[_strip(r)], alpha=0.6, ls='--')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that this is done, we can easily visualize many historical Governer races. The solid line plots the poll history, the dotted line reports the actual result.\n",
      "\n",
      "If this code block fails, you probably have a bug in one of your functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page = requests.get('http://www.realclearpolitics.com/epolls/2010/governor/2010_elections_governor_map.html').text.encode('ascii', 'ignore')\n",
      "\n",
      "for race in find_governor_races(page):\n",
      "    plot_race(race)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'find_governor_races' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-19-86be64f57cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://www.realclearpolitics.com/epolls/2010/governor/2010_elections_governor_map.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfind_governor_races\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplot_race\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'find_governor_races' is not defined"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Briefly summarize these graphs -- how accurate is the typical poll a day before the election? \n",
      "How often does a prediction one month before the election mispredict the actual winner?\n",
      "\n",
      "In most cases the predictions were very straight forward since the gap between the candidates was large. In cases where the gap \n",
      "between candidates was small, predictions still tend to be accurate, mostly. In an odd case of Foley and Malloy, predictions were right\n",
      "through out the race but 1 day before the election, the predictions were not right. However, in Scott and Sink case, predictions were\n",
      "more accurate closer to the race. Another interesting case is of Kitzhaber and Dudley where predictions started to shift a month before\n",
      "the election but then as it went closer to the actual election, the predictions changed back predicting it right. However, mostly all\n",
      "the predictions seem to be right, elections with close cases becomes very hard to predict as you get closer. Also, you have more \n",
      "variance few months before the elections compared to like 3 or 4 days.\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Your summary here**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Part 3: Analysis\n",
      "\n",
      "#### Problem 5\n",
      "\n",
      "You are (finally!) in a position to do some quantitative analysis.\n",
      "\n",
      "We have provided an `error_data` function that builds upon the functions you have written. It computes a new DataFrame with information about polling errors.\n",
      "\n",
      "Use `error_data`, `find_governer_races`, and `pd.concat` to construct a Data Frame summarizing the forecast errors\n",
      "from all the Governor races\n",
      "\n",
      "**Hint** \n",
      "\n",
      "It's best to set `ignore_index=True` in `pd.concat`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def party_from_color(color):\n",
      "    if color in ['#0000CC', '#3B5998']:\n",
      "        return 'democrat'\n",
      "    if color in ['#FF0000', '#D30015']:\n",
      "        return 'republican'\n",
      "    return 'other'\n",
      "\n",
      "\n",
      "def error_data(url):\n",
      "    \"\"\"\n",
      "    Given a Governor race URL, download the poll data and race result,\n",
      "    and construct a DataFrame with the following columns:\n",
      "    \n",
      "    candidate: Name of the candidate\n",
      "    forecast_length: Number of days before the election\n",
      "    percentage: The percent of poll votes a candidate has.\n",
      "                Normalized to that the canddidate percentages add to 100%\n",
      "    error: Difference between percentage and actual race reulst\n",
      "    party: Political party of the candidate\n",
      "    \n",
      "    The data are resampled as necessary, to provide one data point per day\n",
      "    \"\"\"\n",
      "    \n",
      "    id = id_from_url(url)\n",
      "    xml = get_poll_xml(id)\n",
      "    \n",
      "    colors = plot_colors(xml)\n",
      "    if len(colors) == 0:\n",
      "        return pd.DataFrame()\n",
      "    \n",
      "    df = rcp_poll_data(xml)\n",
      "    result = race_result(url)\n",
      "    \n",
      "    #remove non-letter characters from columns\n",
      "    df = df.rename(columns={c: _strip(c) for c in df.columns})\n",
      "    for k, v in result.items():\n",
      "        result[_strip(k)] = v \n",
      "    \n",
      "    candidates = [c for c in df.columns if c is not 'date']\n",
      "        \n",
      "    #turn into a timeseries...\n",
      "    df.index = df.date\n",
      "    \n",
      "    #...so that we can resample at regular, daily intervals\n",
      "    df = df.resample('D')\n",
      "    df = df.dropna()\n",
      "    \n",
      "    #compute forecast length in days\n",
      "    #(assuming that last forecast happens on the day of the election, for simplicity)\n",
      "    forecast_length = (df.date.max() - df.date).values\n",
      "    forecast_length = forecast_length / np.timedelta64(1, 'D')  # convert to number of days\n",
      "    \n",
      "    #compute forecast error\n",
      "    errors = {}\n",
      "    normalized = {}\n",
      "    poll_lead = {}\n",
      "    \n",
      "    for c in candidates:\n",
      "        #turn raw percentage into percentage of poll votes\n",
      "        corr = df[c].values / df[candidates].sum(axis=1).values * 100.\n",
      "        err = corr - result[_strip(c)]\n",
      "        \n",
      "        normalized[c] = corr\n",
      "        errors[c] = err\n",
      "        \n",
      "    n = forecast_length.size\n",
      "    \n",
      "    result = {}\n",
      "    result['percentage'] = np.hstack(normalized[c] for c in candidates)\n",
      "    result['error'] = np.hstack(errors[c] for c in candidates)\n",
      "    result['candidate'] = np.hstack(np.repeat(c, n) for c in candidates)\n",
      "    result['party'] = np.hstack(np.repeat(party_from_color(colors[_strip(c)]), n) for c in candidates)\n",
      "    result['forecast_length'] = np.hstack(forecast_length for _ in candidates)\n",
      "    \n",
      "    result = pd.DataFrame(result)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "function\n",
      "---------\n",
      "all_error_data\n",
      "\n",
      "Calls error_data on all races from find_governer_races(page),\n",
      "and concatenates into a single DataFrame\n",
      "\n",
      "Parameters\n",
      "-----------\n",
      "None\n",
      "\n",
      "Examples\n",
      "--------\n",
      "df = all_error_data()\n",
      "\"\"\"\n",
      "#your code here\n",
      "\n",
      "'''\n",
      "error_data function that builds upon the functions you have written. \n",
      "It computes a new DataFrame with information about polling errors.\n",
      "\n",
      "error_data - information about polling errors\n",
      "find_governer_races - builds a list links of all the election on the html page\n",
      "pd.concat - \n",
      "\n",
      "to construct a Data Frame summarizing the forecast errors from all the Governor races\n",
      "'''\n",
      "\n",
      "#used the url exactly as provided in a previous problem of the hw\n",
      "url = requests.get('http://www.realclearpolitics.com/epolls/2010/governor/2010_elections_governor_map.html').text.encode('ascii', 'ignore')\n",
      "def all_error_data():\n",
      "    test=[]\n",
      "    eList=find_governor_races(url)   #makes a list of all the links on the html page\n",
      "    for i in eList:\n",
      "        try:\n",
      "            test.append(error_data(i))  #runs the already provided error function on all the links through loop and add them to the list test\n",
      "        except ValueError:\n",
      "            pass\n",
      "        \n",
      "    df=pd.concat(test)   #concatenates all the result as one in df\n",
      "    \n",
      "    return df\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = all_error_data()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a histogram of the error of every polling measurement in the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors.error.hist(bins=50)\n",
      "plt.xlabel(\"Polling Error\")\n",
      "plt.ylabel('N')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Problem 6\n",
      "\n",
      "Compute the standard deviation of the polling errors. How much uncertainty is there in the typical RCP poll?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#your code here\n",
      "df=all_error_data()\n",
      "sd=np.std(df['error'])  #accessing only 'error' column from the dataframe and doing standard deviation on it\n",
      "print sd\n",
      "\n",
      "# There is about 5 percent uncertainty in a typical RCP poll given the results were normalized and based on our current data set."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Problem 7\n",
      "\n",
      "Repeat this calculation for the data where `errors.forecast_length < 7` (i.e. the polls within a week of an election). How much more/less accurate are they? How about the data where `errors.forecast_length > 30`? \n",
      "\n",
      "**Comment on this in 1 or 2 sentences**. Does this make sense?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#your code here\n",
      "df=all_error_data()\n",
      "std_len7=[]\n",
      "std_len30=[]\n",
      "\n",
      "for idx, row in df.iterrows():\n",
      "    if row['forecast_length'] < 7:            #standard deviation for one week before the election\n",
      "        std_len7.append(row['error'])\n",
      "    elif row['forecast_length'] > 30:         #standard deviation until 1 month to the election\n",
      "        std_len30.append(row['error'])\n",
      "        \n",
      "sd7=np.std(std_len7)\n",
      "sd30=np.std(std_len30)\n",
      "\n",
      "print sd7\n",
      "print sd30\n",
      "\n",
      "'''Standard deviation is lower closer to the election. I think the poll data is more stronger closer to the elections because \n",
      "people really start thinking about their options and who they are going to vote for as they get closer to the election. As a result,\n",
      " the data on polls start reflecting the outcomes more accurately. That is why you get a lower standard deviation 1 week before the \n",
      " election.'''\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'all_error_data' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-20-c681d4449fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_error_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstd_len7\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstd_len30\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'all_error_data' is not defined"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Problem 8\n",
      "\n",
      "**Bootstrap resampling** is a general purpose way to use empirical data like the `errors` DataFrame to estimate uncertainties. For example, consider the [Viriginia Governor Race](http://www.realclearpolitics.com/epolls/2013/governor/va/virginia_governor_cuccinelli_vs_mcauliffe-3033.html). If we wanted to estimate how likey it is that McAuliffe will win given the current RCP data, the approch would be:\n",
      "\n",
      "1. Pick a large number N of experiments to run (say N=1000).\n",
      "2. For each experiment, randomly select a value from `errors.error`. We are assuming that these numbers represent a reasonable error distribution for the current poll data.\n",
      "3. Assume that the error on McAullife's current polling score is given by this number (and, by extension, the error on Cuccinelli's poll score is the opposite). Calculate who actually wins the election in this simulation.\n",
      "4. Repeat N times, and calculate the percentage of simulations where either candidate wins.\n",
      "\n",
      "Bootstrapping isn't foolproof: it makes the assumption that the previous Governor race errors are representative of the Virginia race, and it does a bad job at estimating very rare events (with only ~30 races in the errors DataFrame, it would be hard to accurately predict probabilities for 1-in-a-million scenarios). Nevertheless, it's a versatile technique.\n",
      "\n",
      "Use bootstrap resampling to estimate how likely it is that each candidate could win the following races.\n",
      "\n",
      " * [Virginia Governor](http://www.realclearpolitics.com/epolls/2013/governor/va/virginia_governor_cuccinelli_vs_mcauliffe-3033.html)\n",
      " * [New Jersey Governor](http://www.realclearpolitics.com/epolls/2013/governor/nj/new_jersey_governor_christie_vs_buono-3411.html)\n",
      " \n",
      "**Summarize your results in a paragraph. What conclusions do you draw from the bootstrap analysis, and what assumptions did you make in reaching this conclusion. What are some limitations of this analysis?**\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#your code here\n",
      "import random\n",
      "\n",
      "df=all_error_data()\n",
      "errors=[]\n",
      "\n",
      "for idx, row in df.iterrows():\n",
      "    errors.append(row['error'])\n",
      "    \n",
      "Virginia_race=race_result('http://www.realclearpolitics.com/epolls/2013/governor/va/virginia_governor_cuccinelli_vs_mcauliffe-3033.html')\n",
      "NewJersey_race=race_result('http://www.realclearpolitics.com/epolls/2013/governor/nj/new_jersey_governor_christie_vs_buono-3411.html')\n",
      "\n",
      "target=NewJersey_race\n",
      "\n",
      "winners=[]\n",
      "winners_list=[]\n",
      "N=10000\n",
      "count=N\n",
      "\n",
      "c1_poll=(target.values()[0])\n",
      "c2_poll=(target.values()[1])\n",
      "\n",
      "while N!=0:\n",
      "    r=random.choice(errors)\n",
      "    \n",
      "    new_c1=c1_poll-r\n",
      "    new_c2=c2_poll+r\n",
      "    \n",
      "    winners.extend((new_c1,new_c2))\n",
      "    w=max(winners)\n",
      "    if winners[0]==w:winners_list.append(target.keys()[0])\n",
      "    elif winners[1]==w:winners_list.append(target.keys()[1])\n",
      "    N-=1\n",
      "    winners=[]\n",
      "\n",
      "c1=float((winners_list.count(target.keys()[0])))/count*100\n",
      "c2=float((winners_list.count(target.keys()[1])))/count*100\n",
      "\n",
      "print \"Chances of winning:\"\n",
      "print target.keys()[0],c1,\"%\"\n",
      "print target.keys()[1],c2,\"%\"\n",
      "\n",
      "\n",
      "'''\n",
      "Chances of winning:\n",
      "McAuliffe 74.3 %\n",
      "Cuccinelli 25.7 %\n",
      "\n",
      "Chances of winning:\n",
      "Christie 97.0 %\n",
      "Buono 3.0 %\n",
      "\n",
      "\n",
      "I am pretty surprised by the result from Virginia Race. The standard deviation is pretty low so I would think the chances of \n",
      "McAuliffe should be higher. Also, My data was missing before when I was still working through it and I only had about 1800 rows. The \n",
      "standard deviation was 9.0+ and I was still getting the same result. After fixing my data with 11,000 entries and the 5.3 standard \n",
      "deviation, I would think the result should change in favor of McAuliffe. \n",
      "\n",
      "Assumptions:\n",
      "1) The random function generating random values is truly random\n",
      "2) Polls data helps accurately predict the outcome\n",
      "3) All polls were equal: same number of participants, demographic, ethnicity, income level, and many such factors didn't play any role\n",
      "\n",
      "Limitations:\n",
      "We didn't assign weights on individual polls based on various factors that seperate them. Also, for us to be able to fairly pick \n",
      "random values from a list and assign it to current polling scenario, it is important that all possible values of errors must exist in\n",
      "that list and that the list should be accumulated randomly and shouldn't favor any certain factor. In this case we are limited by the \n",
      "number of values in our list which is only 11,000 in my case. If you add more election results from past, you start growing your list \n",
      "of errors and in return it makes your bootstraping analysis stronger. \n",
      "\n",
      "'''\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'all_error_data' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-21-c74de3f2f6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_error_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'all_error_data' is not defined"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Your summary here**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parting Thoughts\n",
      "\n",
      "For comparison, most of the predictions in Nate Silver's [presidental forecast](http://fivethirtyeight.blogs.nytimes.com/fivethirtyeights-2012-forecast/) had confidences of >95%. This is more precise than what we can estimate from the RCP poll alone. His approach, however, is the same basic idea (albeit he used many more polls, and carefully calibrated each based on demographic and other information). Homework 2 will dive into some of his techniques further.\n",
      "\n",
      "\n",
      "## How to submit\n",
      "\n",
      "To submit your homework, create a folder named lastname_firstinitial_hw0 and place this notebook file in the folder. If your notebook requires any additional data files to run (it shouldn't), add them to this directory as well. Compress the folder (please use .zip compression) and submit to the CS109 dropbox in the appropriate folder. If we cannot access your work because these directions are not followed correctly, we will not grade your work."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "*css tweaks in this cell*\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "</style>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}